{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1YM51_d0KDWdJHtcIfk5VV3GLkAEw4TYi","timestamp":1767444075722}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# <font size=\"7\"> **Assignment-6**</font>\n","I hope this assignment will give you clarity on how mathematical models like **Multilayer Perceptrons (MLP)** can be made from scratch using **PyTorch** & can be used to solve complex, non-linear geometric problems **without relying on black-box libraries**.\n","\n","---\n","# ⚫ **Mission Critical: The Exclusion Zone Protocol**\n","\n","**Date:** Year 2142  \n","**Location:** Exoplanet *Kepler-186f*   **Clearance:** IITians\n","\n","---\n","\n","### **⚫ The Story**\n","Humanity has colonized the distant exoplanet *Kepler-186f*. While the surface is habitable, the planet's magnetic core is unstable. The **Global Defense Council (GDC)** has identified a dangerous phenomenon known as the **\"Radiation Ring.\"**\n","\n","Sensors indicate that the safe zones on the planet follow a peculiar geometry:\n","* ⚫ **The Core Zone:** Distance $< 2$ km from the colony center (Safe).\n","* ⚫ **The Outer Wilds:** Distance $> 4$ km from the colony center (Safe).\n","* ⚫ **The Dead Zone:** The region **between 2 km and 4 km** is flooded with lethal gamma radiation.\n","\n","Your engineering team has deployed **3,000 sensor drones** across the colony to map this danger. Each drone reports its coordinates $(x, y)$ and a binary label:\n","* `1`: Radiation Detected (Dead Zone)\n","* `0`: Safe Zone\n","\n"," **⚫ The Problem:** The sensors are cheap and prone to interference. Approximately **5%** of the drones are malfunctioning and reporting the wrong safety status (noise). The GDC mainframe is a legacy system that forbids the use of modern \"Neural Libraries\" (i.e., you cannot use `torch.nn` or `torch.optim`). You must build a **Multi-Layer Perceptron (MLP) from scratch** to filter out the noise and mathematically define the Exclusion Zone boundaries using **PyTorch**. ( Hint: You know this is a binary classification problem, which Loss function would you use?? )\n","\n","---\n","\n","### **⚫ Your Objective**\n","\n","1.  **Initialize the System:** Use your **Group Number** as the random seed. This ensures your team works on a unique sensor distribution pattern.\n","2.  **Architect the Filter:** Construct a neural network with **3 hidden layers** (16 neurons each) to learn the non-linear \"donut\" shape of the Dead Zone.\n","3.  **Manual Calibration:** You cannot use auto-optimizers. You must manually calculate the gradients (Backpropagation) and update the system weights using **Gradient Descent**.\n","4.  **Verify Integrity:** Split your sensor data (70% training, 30% validation). Prove that your system doesn't just memorize the malfunctioning sensors (overfitting) but actually learns the geometric shape of the Dead Zone.\n","\n","---\n","\n","## ⚫ Engineering Constraints (Read Carefully)\n","\n","**1. Restricted Modules**\n","*  **Forbidden:** You are strictly forbidden from importing `torch.nn` (Layers/Loss) or `torch.optim` (Optimizers).\n","*  **Allowed:** `import torch`, `import matplotlib.pyplot`, `import pandas`, `import numpy`, using `sklearn`.\n","\n","\n","**2. The Mechanics**\n","* **Forward Pass:** Must be implemented using raw matrix multiplication (`torch.matmul`) and bias addition.\n","* **Backward Pass:** You **MAY** use `loss.backward()` to compute gradients automatically (Autograd).\n","* **Optimization:** You **MUST** implement the weight updates manually (Stochastic Gradient Descent).\n","    > `w_new = w_old - learning_rate * w_old.grad`\n","\n","**3. Loss Function**\n","Since `torch.nn` is banned, you must implement **Binary Cross Entropy** manually using basic tensor math.\n","\n","$$Loss = -\\frac{1}{N} \\sum_{i=1}^{N} [y_i \\cdot \\log(\\hat{y}_i) + (1-y_i) \\cdot \\log(1-\\hat{y}_i)]$$\n","\n","* **Note:** Ensure you handle the log of zero (numerical stability) or use `torch.clamp` to avoid `NaN` errors.\n","\n","**4. Visual Proof:** Your final output must include a Decision Boundary Map showing the \"Donut\" shape.\n","\n","\n","---\n","\n","### ⚫ **The GDC Dashboard (Required Output)**\n","\n","\n","\n","The Global Defense Council requires visual confirmation that your system is stable before we can upload it to the drone fleet. You must generate a **3-Panel Heads-Up Display (HUD)** containing the following telemetry:\n","\n","**1. System Error Trajectory (Loss Plot)**\n","* **Mission:** Plot the **Training Loss** (Blue) vs. **Validation Loss** (Orange) over all epochs.\n","* **Why:** We need to confirm that the system is actually learning and not just diverging (exploding gradients).\n","\n","**2. Integrity Check (Accuracy Plot)**\n","* **Mission:** Plot the **Training Accuracy** vs. **Validation Accuracy**.\n","* **Why:** If Training Accuracy is high (95%) but Validation Accuracy is low (80%), you have failed to generalize. This is a sign of **Overfitting**—memorizing sensor noise instead of the Radiation Ring.\n","\n","**3. Geospatial Threat Map (Decision Boundary)**\n","* **Mission:** Visualize the **Validation Set** on a 2D map.\n","* **Overlay:** Draw the neural network's **Decision Boundary** (the contours where confidence = 0.5).\n","* **Why:** The Commander needs to *see* the \"Donut\" shape. If your boundary looks like a jagged mess, the model is rejected.\n","\n","---"],"metadata":{"id":"sqmYfcSkoQPH"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","# ===========================================================\n","# PART 1: Data Generation (The Exclusion Zone)\n","# ===========================================================\n","GROUP_NUMBER = 13\n","\n","# Set seed for reproducibility\n","torch.manual_seed(GROUP_NUMBER)\n","np.random.seed(GROUP_NUMBER)\n","\n","def generate_data(n_samples=3000):\n","\n","    X = (torch.rand(n_samples, 2) * 10) - 5\n","\n","    # Calculate distance from center (radius)\n","    radius = torch.sqrt(X[:, 0]**2 + X[:, 1]**2)\n","\n","    # Assign Labels: 1 if inside the Dead Zone, 0 otherwise\n","    y = ((radius > 2) & (radius < 4)).float().view(-1, 1)\n","\n","    # Add 5% Noise (Malfunctioning Drones)\n","    n_noise = int(0.05 * n_samples)\n","    noise_indices = torch.randperm(n_samples)[:n_noise]\n","    y[noise_indices] = 1 - y[noise_indices] # Flip labels\n","\n","    return X, y\n","\n","# Generate the dataset\n","X_full, y_full = generate_data(3000)\n","\n","print(f\"Data Generated: {X_full.shape} samples.\")\n","print(f\"Target Generated: {y_full.shape} labels.\")"],"metadata":{"id":"rP6_Oh-3OJ9C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767444584845,"user_tz":-330,"elapsed":4264,"user":{"displayName":"Alok Kumar","userId":"00013807134898981833"}},"outputId":"0ae4c4ab-d56c-4395-eac5-3e86500fd271"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Data Generated: torch.Size([3000, 2]) samples.\n","Target Generated: torch.Size([3000, 1]) labels.\n"]}]},{"cell_type":"code","source":["# PART 2: Training\n","\n","split = int(0.8 * len(X_full))\n","X_train, X_val = X_full[:split], X_full[split:]\n","y_train, y_val = y_full[:split], y_full[split:]\n","\n","print(\"Train samples:\", X_train.shape[0])\n","print(\"Validation samples:\", X_val.shape[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NvANSBdb5X1V","executionInfo":{"status":"ok","timestamp":1767444590484,"user_tz":-330,"elapsed":532,"user":{"displayName":"Alok Kumar","userId":"00013807134898981833"}},"outputId":"13890b6b-9497-4384-9060-d01bb7f09ffc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Train samples: 2400\n","Validation samples: 600\n"]}]},{"cell_type":"code","source":["# PART 3: Model Initialization\n","\n","def init_weights(in_dim, out_dim):\n","    return torch.randn(in_dim, out_dim) * 0.01, torch.zeros(1, out_dim)\n","\n","W1, b1 = init_weights(2, 16)\n","W2, b2 = init_weights(16, 8)\n","W3, b3 = init_weights(8, 1)\n"],"metadata":{"id":"bBDfF2nN5eyD","executionInfo":{"status":"ok","timestamp":1767444611669,"user_tz":-330,"elapsed":722,"user":{"displayName":"Alok Kumar","userId":"00013807134898981833"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# PART 4: Activation Functions\n","def relu(x):\n","    return torch.clamp(x, min=0)\n","\n","def relu_derivative(x):\n","    return (x > 0).float()\n","\n","def sigmoid(x):\n","    return 1 / (1 + torch.exp(-x))\n"],"metadata":{"id":"i-KJMtIT6IxZ","executionInfo":{"status":"ok","timestamp":1767444639941,"user_tz":-330,"elapsed":672,"user":{"displayName":"Alok Kumar","userId":"00013807134898981833"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# PART 5: Loss Function\n","\n","def binary_cross_entropy(y, y_hat):\n","    eps = 1e-8\n","    return -torch.mean(\n","        y * torch.log(y_hat + eps) +\n","        (1 - y) * torch.log(1 - y_hat + eps)\n","    )\n"],"metadata":{"id":"2rWYntd66PaY","executionInfo":{"status":"ok","timestamp":1767444658374,"user_tz":-330,"elapsed":508,"user":{"displayName":"Alok Kumar","userId":"00013807134898981833"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# PART 6: Forward Pass\n","\n","def forward(X):\n","    Z1 = X @ W1 + b1\n","    A1 = relu(Z1)\n","\n","    Z2 = A1 @ W2 + b2\n","    A2 = relu(Z2)\n","\n","    Z3 = A2 @ W3 + b3\n","    y_hat = sigmoid(Z3)\n","\n","    return Z1, A1, Z2, A2, y_hat\n"],"metadata":{"id":"79bkbBTL6UGV","executionInfo":{"status":"ok","timestamp":1767444677618,"user_tz":-330,"elapsed":491,"user":{"displayName":"Alok Kumar","userId":"00013807134898981833"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# PART 7: Training\n","\n","lr = 0.01\n","epochs = 3000\n","\n","for epoch in range(epochs):\n","\n","    # Forward\n","    Z1, A1, Z2, A2, y_hat = forward(X_train)\n","\n","    loss = binary_cross_entropy(y_train, y_hat)\n","\n","    # Backpropagation\n","    dZ3 = y_hat - y_train\n","    dW3 = A2.T @ dZ3 / len(X_train)\n","    db3 = dZ3.mean(0, keepdim=True)\n","\n","    dA2 = dZ3 @ W3.T\n","    dZ2 = dA2 * relu_derivative(Z2)\n","    dW2 = A1.T @ dZ2 / len(X_train)\n","    db2 = dZ2.mean(0, keepdim=True)\n","\n","    dA1 = dZ2 @ W2.T\n","    dZ1 = dA1 * relu_derivative(Z1)\n","    dW1 = X_train.T @ dZ1 / len(X_train)\n","    db1 = dZ1.mean(0, keepdim=True)\n","\n","    # Update\n","    W3 -= lr * dW3\n","    b3 -= lr * db3\n","    W2 -= lr * dW2\n","    b2 -= lr * db2\n","    W1 -= lr * dW1\n","    b1 -= lr * db1\n","\n","    if epoch % 500 == 0:\n","        print(f\"Epoch {epoch} | Loss: {loss.item():.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-x_thkg46Ysj","executionInfo":{"status":"ok","timestamp":1767444700353,"user_tz":-330,"elapsed":4408,"user":{"displayName":"Alok Kumar","userId":"00013807134898981833"}},"outputId":"9bc2cfa0-26dd-40c4-9f26-ab8cbc1461bb"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | Loss: 0.6931\n","Epoch 500 | Loss: 0.6730\n","Epoch 1000 | Loss: 0.6713\n","Epoch 1500 | Loss: 0.6711\n","Epoch 2000 | Loss: 0.6711\n","Epoch 2500 | Loss: 0.6711\n"]}]},{"cell_type":"code","source":["# PART 8: Accuracy Evaluation\n","\n","def accuracy(X, y):\n","    _, _, _, _, y_hat = forward(X)\n","    return ((y_hat > 0.5) == y).float().mean()\n","\n","print(\"training accuracy:\", accuracy(X_train, y_train).item())\n","print(\"validation accuracy:\", accuracy(X_val, y_val).item())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae3x2Av86e1i","executionInfo":{"status":"ok","timestamp":1767444929886,"user_tz":-330,"elapsed":5,"user":{"displayName":"Alok Kumar","userId":"00013807134898981833"}},"outputId":"668eff07-1124-47d7-b662-abfcf7a119e4"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["training accuracy: 0.6045833230018616\n","validation accuracy: 0.6483333110809326\n"]}]},{"cell_type":"code","source":["# ==============================================================================\n","# Code from here. Best of luckk :)\n","# =============================================================================="],"metadata":{"id":"sgzsnDTloTQ7"},"execution_count":null,"outputs":[]}]}